{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84941d3",
   "metadata": {},
   "source": [
    "Write a program to implement the naïve Bayesian classifier for a sample training data set stored as a.CSV file. \n",
    "Compute the accuracy of the classifier, considering few test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7ca869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41019cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1594a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./datasets/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14add19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f95dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Outcome',axis=1)\n",
    "Y=df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b4ec857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3283866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7cf4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GaussianNB()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68af245b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1]\n",
      "Actual:    [0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1]\n",
      "Accuracy : 0.7597402597402597\n",
      "Precision: 0.6071428571428571\n",
      "Recall   : 0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Predicted:\", y_pred.tolist())\n",
    "print(\"Actual:   \", y_test.tolist())\n",
    "\n",
    "print(\"Accuracy :\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall   :\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30e22d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70720725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5728 entries, 0 to 5727\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5728 non-null   object\n",
      " 1   spam    5728 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 89.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/emails.csv\")\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "055c614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"].astype(str)\n",
    "y = df['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b60e1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "180a7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac91465",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(stop_words=\"english\",ngram_range=(1,2),max_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09182c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec=vectorizer.fit_transform(X_train)\n",
    "x_test_vec=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c31ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '2000' '2001' 'cc' 'com' 'ect' 'ect ect' 'enron' 'group' 'hou'\n",
      " 'hou ect' 'kaminski' 'know' 'pm' 'research' 'subject' 'thanks' 'time'\n",
      " 'vince' 'vince kaminski']\n",
      "['2000' '2001' 'cc' 'com' 'ect' 'ect ect' 'enron' 'group' 'hou']\n",
      "(20,)\n",
      "\n",
      "Document-Term Matrix:\n",
      "[[0 2 0 ... 0 4 2]\n",
      " [0 0 3 ... 0 4 3]\n",
      " [0 0 0 ... 0 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 1 1 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "feature_name=vectorizer.get_feature_names_out()\n",
    "print(feature_name)\n",
    "print(feature_name[1:10])\n",
    "print(feature_name.shape)\n",
    "print(\"\\nDocument-Term Matrix:\")\n",
    "print(x_train_vec.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1413df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_vec shape: (4582, 20)\n",
      "x_test_vec shape : (1146, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train_vec shape:\", x_train_vec.shape)\n",
    "print(\"x_test_vec shape :\", x_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f23fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_train_vec, y_train)\n",
    "y_pred = model.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "647c28b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Important Spam Words  |  No Spam Words:\n",
      "subject     |      enron\n",
      "com     |      ect\n",
      "time     |      subject\n",
      "10     |      vince\n",
      "know     |      hou\n",
      "group     |      hou ect\n",
      "research     |      2000\n",
      "thanks     |      ect ect\n",
      "2000     |      kaminski\n",
      "pm     |      com\n",
      "2001     |      vince kaminski\n",
      "hou     |      cc\n",
      "cc     |      pm\n",
      "vince     |      2001\n",
      "ect     |      research\n"
     ]
    }
   ],
   "source": [
    "spam_prob=model.feature_log_prob_[1]\n",
    "nonspam_prob=model.feature_log_prob_[0]\n",
    "top_indices_spam = spam_prob.argsort()[-15:]\n",
    "top_indices_nonspam = nonspam_prob.argsort()[-15:]\n",
    "\n",
    "print(\"Most Important Spam Words  |  No Spam Words:\")\n",
    "for i, j in zip(reversed(top_indices_spam), reversed(top_indices_nonspam)):\n",
    "    print(feature_name[i], \"    |     \", feature_name[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89794b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy : 0.9075043630017452\n",
      "Precision: 0.7383419689119171\n",
      "Recall   : 0.9827586206896551\n",
      "F1 Score : 0.8431952662721893\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAccuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1 Score :\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d76d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10' '2000' '2001' 'cc' 'com' 'ect' 'ect ect' 'enron' 'group' 'hou'\n",
      " 'hou ect' 'kaminski' 'know' 'pm' 'research' 'subject' 'thanks' 'time'\n",
      " 'vince' 'vince kaminski']\n",
      "x_train_vec shape: (4582, 20)\n",
      "x_test_vec shape : (1146, 20)\n",
      "\n",
      "Accuracy : 0.9118673647469459\n",
      "Precision: 0.8203389830508474\n",
      "Recall   : 0.8344827586206897\n",
      "F1 Score : 0.8273504273504273\n",
      "\n",
      "Most Important Spam Words  |  No Spam Words:\n",
      "subject     |      enron\n",
      "com     |      vince\n",
      "time     |      subject\n",
      "10     |      ect\n",
      "know     |      2000\n",
      "group     |      com\n",
      "thanks     |      kaminski\n",
      "research     |      thanks\n",
      "2000     |      research\n",
      "2001     |      2001\n",
      "pm     |      know\n",
      "hou     |      time\n",
      "cc     |      vince kaminski\n",
      "ect     |      hou\n",
      "vince     |      pm\n"
     ]
    }
   ],
   "source": [
    "#  TfidfVectorizer Counts words but also measures how important each word is\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "df = pd.read_csv(\"./datasets/emails.csv\")\n",
    "\n",
    "X = df[\"text\"].astype(str)\n",
    "y = df[\"spam\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------- TF-IDF Vectorization --------\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2), max_features=20)\n",
    "\n",
    "x_train_vec = vectorizer.fit_transform(X_train)\n",
    "x_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "feature_name = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(feature_name)\n",
    "print(\"x_train_vec shape:\", x_train_vec.shape)\n",
    "print(\"x_test_vec shape :\", x_test_vec.shape)\n",
    "\n",
    "# -------- Train Naïve Bayes --------\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train_vec, y_train)\n",
    "\n",
    "# -------- Predict --------\n",
    "y_pred = model.predict(x_test_vec)\n",
    "\n",
    "# -------- Accuracy Metrics --------\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nAccuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1 Score :\", f1)\n",
    "\n",
    "# -------- Find Important Words --------\n",
    "spam_prob = model.feature_log_prob_[1]\n",
    "nonspam_prob = model.feature_log_prob_[0]\n",
    "\n",
    "top_indices_spam = spam_prob.argsort()[-15:]\n",
    "top_indices_nonspam = nonspam_prob.argsort()[-15:]\n",
    "\n",
    "print(\"\\nMost Important Spam Words  |  No Spam Words:\")\n",
    "for i, j in zip(reversed(top_indices_spam), reversed(top_indices_nonspam)):\n",
    "    print(feature_name[i], \"    |     \", feature_name[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309b0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0076f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "heartDisease = pd.read_csv('./datasets/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db94482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Attributes and datatypes\n",
      "age               int64\n",
      "sex               int64\n",
      "cp                int64\n",
      "trestbps          int64\n",
      "chol              int64\n",
      "fbs               int64\n",
      "restecg           int64\n",
      "thalach           int64\n",
      "exang             int64\n",
      "oldpeak         float64\n",
      "slope             int64\n",
      "ca               object\n",
      "thal             object\n",
      "heartdisease      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('\\n Attributes and datatypes')\n",
    "print(heartDisease.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d95ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     age  sex  exang  cp  restecg  chol\n",
      "0     63    1      0   1        2   233\n",
      "1     67    1      1   4        2   286\n",
      "2     67    1      1   4        2   229\n",
      "3     37    1      0   3        0   250\n",
      "4     41    0      0   2        2   204\n",
      "..   ...  ...    ...  ..      ...   ...\n",
      "298   45    1      0   1        0   264\n",
      "299   68    1      0   4        0   193\n",
      "300   57    1      1   4        0   131\n",
      "301   57    0      0   2        2   236\n",
      "302   38    1      0   3        0   175\n",
      "\n",
      "[303 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(heartDisease[['age','sex','exang','cp','restecg','chol']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23ca4af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample instances from the dataset are given below\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
      "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
      "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
      "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
      "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
      "\n",
      "  ca thal  heartdisease  \n",
      "0  0    6             0  \n",
      "1  3    3             2  \n",
      "2  2    7             1  \n",
      "3  0    3             0  \n",
      "4  0    3             0  \n"
     ]
    }
   ],
   "source": [
    "heartDisease = heartDisease.replace('?',np.nan)\n",
    "print('Sample instances from the dataset are given below')\n",
    "print(heartDisease.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0b78c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pgmpy.models import DiscreteBayesianNetwork\n",
    "#Creat Model- Bayesian Network \n",
    "train_df, test_df = train_test_split(heartDisease, test_size=0.2, random_state=42, stratify=heartDisease['heartdisease'])\n",
    "model = DiscreteBayesianNetwork([('age','heartdisease'),('sex','heartdisease'),(\n",
    "'exang','heartdisease'),('cp','heartdisease'),('restecg','heartdisease'),('chol','heartdisease')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd05f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pgmpy: Datatype (N=numerical, C=Categorical Unordered, O=Categorical Ordered) inferred from data: \n",
      " {'age': 'N', 'sex': 'N', 'cp': 'N', 'trestbps': 'N', 'chol': 'N', 'fbs': 'N', 'restecg': 'N', 'thalach': 'N', 'exang': 'N', 'oldpeak': 'N', 'slope': 'N', 'ca': 'C', 'thal': 'C', 'heartdisease': 'N'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Learning CPD using Maximum likelihood estimators\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pgmpy.models.DiscreteBayesianNetwork.DiscreteBayesianNetwork at 0x1bbe393c3b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other estimators are BayesianEstimator, HillClimbSearch\n",
    "print('\\n Learning CPD using Maximum likelihood estimators')\n",
    "model.fit(heartDisease,estimator=MaximumLikelihoodEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d00c7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Inference engine. Other Inference Engines are BeliefPropagation, GibbsSampling\n",
    "# -----------------------------\n",
    "infer = VariableElimination(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "caf33205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diagnosis Probability for example patient:\n",
      "+-----------------+---------------------+\n",
      "| heartdisease    |   phi(heartdisease) |\n",
      "+=================+=====================+\n",
      "| heartdisease(0) |              0.2000 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(1) |              0.2000 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(2) |              0.2000 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(3) |              0.2000 |\n",
      "+-----------------+---------------------+\n",
      "| heartdisease(4) |              0.2001 |\n",
      "+-----------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "example_patient = {'restecg':1}\n",
    "\n",
    "result = infer.query(variables=['heartdisease'], evidence=example_patient)\n",
    "print(\"\\nDiagnosis Probability for example patient:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64434b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Predict on test set (basic evaluation)\n",
    "# We'll predict target by taking whichever probability is higher\n",
    "# -----------------------------\n",
    "y_true = test_df['heartdisease'].tolist()\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    row = test_df.iloc[i]\n",
    "    evidence = {\n",
    "        'age': int(row['age']),\n",
    "        'sex': int(row['sex']),\n",
    "        'restecg': int(row['restecg']),\n",
    "        'chol': int(row['chol']),\n",
    "        'exang':int(row['exang']),\n",
    "        'cp':int(row['cp'])\n",
    "    }\n",
    "\n",
    "    q = infer.query(variables=['heartdisease'], evidence=evidence)\n",
    "    # q.values[0] = P(target=0), q.values[1] = P(target=1)\n",
    "    pred_class = 1 if q.values[1] > q.values[0] else 0\n",
    "    y_pred.append(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82458a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation on Test Data ===\n",
      "Accuracy : 0.7213114754098361\n",
      "Precision: 0.5373770491803279\n",
      "Recall   : 0.7213114754098361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\mtech machine learning\\Lab Programs\\Sample\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred,average='weighted')\n",
    "rec = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(\"\\n=== Evaluation on Test Data ===\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
